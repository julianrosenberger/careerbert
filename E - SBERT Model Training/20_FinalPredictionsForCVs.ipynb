{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21156,
     "status": "ok",
     "timestamp": 1689841319051,
     "user": {
      "displayName": "Lukas Wolfrum",
      "userId": "10737638498661133063"
     },
     "user_tz": -120
    },
    "id": "oD-JfEef7BtT",
    "outputId": "e7a2ec49-cd14-4b16-815e-502c10865633"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# %cd /content/drive/MyDrive/TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 38046,
     "status": "ok",
     "timestamp": 1689841357091,
     "user": {
      "displayName": "Lukas Wolfrum",
      "userId": "10737638498661133063"
     },
     "user_tz": -120
    },
    "id": "KzVdQ9C37ncM"
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !pip install sentence_transformers\n",
    "# !pip install pypdf\n",
    "# !pip install xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17884,
     "status": "ok",
     "timestamp": 1689841374961,
     "user": {
      "displayName": "Lukas Wolfrum",
      "userId": "10737638498661133063"
     },
     "user_tz": -120
    },
    "id": "Ef9B19mQ7T4q"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from helpers import *\n",
    "from sentence_transformers import SentenceTransformer,util\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from pypdf import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1053,
     "status": "ok",
     "timestamp": 1689841376011,
     "user": {
      "displayName": "Lukas Wolfrum",
      "userId": "10737638498661133063"
     },
     "user_tz": -120
    },
    "id": "eQYSveiE7aX_"
   },
   "outputs": [],
   "source": [
    "# Load ESCO jobs data\n",
    "jobs = load_json(\"../00_data/ESCO/ESCO_JOBS_ALL.json\")\n",
    "esco_lookup = {}\n",
    "for job in jobs:\n",
    "  esco_lookup[job[\"jobid_esco\"]] = job[\"jobtitle\"]\n",
    "  esco_lookup[job[\"jobtitle\"]] = job[\"jobid_esco\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b_Z0pgsvyPZh"
   },
   "source": [
    "# Similarity Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1689841376012,
     "user": {
      "displayName": "Lukas Wolfrum",
      "userId": "10737638498661133063"
     },
     "user_tz": -120
    },
    "id": "HWTxmW8b1Dwp"
   },
   "outputs": [],
   "source": [
    "# Calculate TF-IDF similarity\n",
    "def calculate_tfidf_similarity(inputtext):\n",
    "  if isinstance(inputtext,str):\n",
    "    inputtext = [inputtext]\n",
    "\n",
    "  vectorizer = load_pickle(\"../00_data/TF-IDF_Vectorizer/1_vectorizer.pkl\")\n",
    "  tfidf_matrix = load_pickle(\"../00_data/TF-IDF_Vectorizer/1_tfidf_matrix.pkl\")\n",
    "  escoids = load_pickle(\"../00_data/TF-IDF_Vectorizer/1_escoids.pkl\")\n",
    "\n",
    "  inputtfidf = vectorizer.transform(inputtext)\n",
    "  cosine_sim = cosine_similarity(inputtfidf, tfidf_matrix)\n",
    "  cossim_df = pd.DataFrame(cosine_sim, columns = escoids, index=[\"similarity\"]).T.sort_values(by=\"similarity\",ascending=False).reset_index()\n",
    "  cossim_df.columns = [\"esco_id\",\"similarity\"]\n",
    "  cossim_df[\"jobtitle\"] = cossim_df[\"esco_id\"].map(esco_lookup)\n",
    "\n",
    "\n",
    "  return cosine_sim,cossim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 265,
     "status": "ok",
     "timestamp": 1689842477062,
     "user": {
      "displayName": "Lukas Wolfrum",
      "userId": "10737638498661133063"
     },
     "user_tz": -120
    },
    "id": "oLqSzSMY7wtM"
   },
   "outputs": [],
   "source": [
    "# Load a single CV from a PDF file\n",
    "def load_single_cv(filepath):\n",
    "  cv = \"\"\n",
    "  reader = PdfReader(filepath)\n",
    "\n",
    "  pages = reader.pages\n",
    "  for i in range(len(pages)):\n",
    "      page = reader.pages[i].extract_text().strip()\n",
    "      cv +=page\n",
    "  return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 294,
     "status": "ok",
     "timestamp": 1689841849527,
     "user": {
      "displayName": "Lukas Wolfrum",
      "userId": "10737638498661133063"
     },
     "user_tz": -120
    },
    "id": "dNzIOOVOynsu"
   },
   "outputs": [],
   "source": [
    "# Predict similarity between query and job embeddings\n",
    "def predict_similarity(query, model,embeddings,TFIDF=False,topn=20):\n",
    "\n",
    "  # uses the provided model to create a sentence embedding\n",
    "  query_embedding = model.encode(query)\n",
    "  # compares the query embedding tothe corpus of job centroids\n",
    "  similarity_calc = util.cos_sim(query_embedding, embeddings[\"job_centroid\"][\"embeddings\"])\n",
    "\n",
    "  # if TFIDF is set to true\n",
    "  if TFIDF == True:\n",
    "    #gets the maximum cosine similarity of the sbert model multiplies it with 0.2 (experimental value)\n",
    "    max_influence_tfidf = (max(map(max, similarity_calc))).item()*0.2\n",
    "    # calculates the TFIDF similarity\n",
    "    similarities_tfidf = calculate_tfidf_similarity(query)[0]\n",
    "\n",
    "    #check if tfidf found any match, otherwise skip adding TFIDF\n",
    "    #if similarities_tfidf.all() != 0:\n",
    "      #normalizes all values to \"max_influence_tfidf\"\n",
    "    similarities_tfidf *= (max_influence_tfidf/similarities_tfidf.max())\n",
    "      #adds both similarity matrices together\n",
    "    similarity_calc = np.add(similarity_calc,similarities_tfidf)\n",
    "\n",
    "  # wraps the similarity_calc into a dataframe and adds the esco ids, also sorts the results according to similarity\n",
    "  results = pd.DataFrame(similarity_calc, columns=embeddings[\"job_centroid\"][\"esco_id\"]).T.reset_index()\n",
    "  results[\"jobtitle\"] = embeddings[\"job_centroid\"][\"jobtitle\"]\n",
    "  results.columns = [\"esco_id\", \"similarity\",\"jobtitle\"]\n",
    "  results = results.sort_values(by=\"similarity\",ascending=False).reset_index(drop=True)\n",
    "\n",
    "  return results[[\"jobtitle\",\"esco_id\",\"similarity\"]].iloc[:topn]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuYGaJO5AEol"
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3227,
     "status": "ok",
     "timestamp": 1689841676532,
     "user": {
      "displayName": "Lukas Wolfrum",
      "userId": "10737638498661133063"
     },
     "user_tz": -120
    },
    "id": "JTqeteCn8ciH"
   },
   "outputs": [],
   "source": [
    "# Load the pre-trained model\n",
    "modelpath = \"../00_data/SBERT_Models/models/gbert_batch32_woTSDAE_2e-05_f10/\"\n",
    "model = SentenceTransformer(modelpath)\n",
    "embeddings = load_pickle(f\"{modelpath}/embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check embeddings keys\n",
    "embeddings.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 470,
     "status": "ok",
     "timestamp": 1689842503339,
     "user": {
      "displayName": "Lukas Wolfrum",
      "userId": "10737638498661133063"
     },
     "user_tz": -120
    },
    "id": "F14i5lyNdiHU"
   },
   "outputs": [],
   "source": [
    "# Load a CV for testing\n",
    "path_to_cv = f\"../00_data/CVs/CV_1.pdf\"\n",
    "cv = load_single_cv(path_to_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "executionInfo": {
     "elapsed": 6323,
     "status": "ok",
     "timestamp": 1689842513965,
     "user": {
      "displayName": "Lukas Wolfrum",
      "userId": "10737638498661133063"
     },
     "user_tz": -120
    },
    "id": "AGM6FQCCyUkn",
    "outputId": "a4b68d55-6a44-4129-f814-5752da3d9074"
   },
   "outputs": [],
   "source": [
    "# Predict similarity for the loaded CV\n",
    "predict_similarity(cv,model,embeddings,TFIDF = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9_1Ms6d5GcC"
   },
   "source": [
    "# Load CVs for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 223,
     "status": "ok",
     "timestamp": 1689842478395,
     "user": {
      "displayName": "Lukas Wolfrum",
      "userId": "10737638498661133063"
     },
     "user_tz": -120
    },
    "id": "dt_OX6tJ5lzd"
   },
   "outputs": [],
   "source": [
    "# Define models and evaluation path\n",
    "modellist = [\n",
    "             \"jobgbert_batch32_woTSDAE_2e-05_f10\",\n",
    "             \"gbert_batch32_woTSDAE_2e-05_f10\"\n",
    "             \n",
    "             ]\n",
    "path_for_eval = \"../00_data/CV_Evaluation/results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fLR51UzAAHLo"
   },
   "source": [
    "## Make final Predictions, save as Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickle file\n",
    "def load_pickle(filepath):\n",
    "    with open(filepath, \"rb\") as fIn:\n",
    "        stored_data = pickle.load(fIn)\n",
    "    return stored_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import joblib\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 70226,
     "status": "ok",
     "timestamp": 1686729375137,
     "user": {
      "displayName": "Lukas Wolfrum",
      "userId": "10737638498661133063"
     },
     "user_tz": -120
    },
    "id": "nUeSPwM65Ik6",
    "outputId": "5dc70d67-b664-48c1-c888-e7663d28fe1f"
   },
   "outputs": [],
   "source": [
    "# Evaluate CVs and save predictions\n",
    "for i in range(1,6):\n",
    "  #opening cvs\n",
    "  print(f\"Evaluating CV {i}\")\n",
    "  path_to_cv = f\"../00_data/CVs/CV_{i}.pdf\"\n",
    "  cv = load_single_cv(path_to_cv)\n",
    "  results = {}\n",
    "  model_dict = {}\n",
    "  #iterating over models\n",
    "  for model_no, model_name in enumerate(modellist):\n",
    "    print(model_name)\n",
    "    model = SentenceTransformer(f\"../00_data/SBERT_Models/models/{model_name}\")\n",
    "    embeddings = load_pickle(f\"../00_data/SBERT_Models/models/{model_name}/embeddings.pkl\")\n",
    "\n",
    "    #make predicitions with current model with tfidf\n",
    "    results[f\"M{model_no+1}_w_tfidf\"] = predict_similarity(cv,model,embeddings,TFIDF=True,topn=20)\n",
    "    #make predicitions with current model without tfidf\n",
    "    results[f\"M{model_no+1}_wo_tfidf\"] = predict_similarity(cv,model,embeddings,TFIDF=False,topn=20)\n",
    "    #modelnames are too long for excel sheet names, create a lookup to keep track of models\n",
    "    model_dict[f\"M{model_no+1}\"] = model_name\n",
    "\n",
    "    #save everything in one excel file per CV\n",
    "    with pd.ExcelWriter(f\"{path_for_eval}CV_{i}_x.xlsx\", engine='xlsxwriter') as writer:\n",
    "      for k, v in results.items():\n",
    "        v.to_excel(writer, sheet_name=k)\n",
    "      pd.Series(list(set(pd.concat(results.values())[\"jobtitle\"])),name=\"jobtitle\").to_excel(writer,sheet_name=\"concat\")\n",
    "      pd.Series(model_dict).to_excel(writer,sheet_name=\"model_lookup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CV data\n",
    "cvs = pd.DataFrame(load_json(\"../00_data/CVs/cv_data.json\"))\n",
    "cvs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode CVs using the model\n",
    "cv_embeddings = model.encode(cvs[\"text\"].tolist(), show_progress_bar=True)\n",
    "cvs[\"embeddings\"] = cv_embeddings.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match CVs with Job Centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load job centroids\n",
    "job_centroids = pd.DataFrame(load_json(\"../00_data/SBERT_Models/job_centroids.json\"))\n",
    "job_centroids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity between CVs and job centroids\n",
    "similarities = cosine_similarity(\n",
    "    np.array(cvs[\"embeddings\"].tolist()),\n",
    "    np.array(job_centroids[\"embeddings\"].tolist())\n",
    ")\n",
    "cvs[\"job_matches\"] = [list(sim) for sim in similarities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results\n",
    "write_pickle(\"../00_data/Results/cv_job_matches.pkl\", cvs)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN/0cnQpM25CIDuXH7TNpuR",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
