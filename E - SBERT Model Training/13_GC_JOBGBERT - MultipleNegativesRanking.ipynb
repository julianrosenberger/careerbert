{"cells":[{"cell_type":"markdown","metadata":{"id":"gWOOQk0qg2Yz"},"source":["# Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36651,"status":"ok","timestamp":1681799362334,"user":{"displayName":"Lukas Wolfrum","userId":"10737638498661133063"},"user_tz":-120},"id":"-aOtwdg3jehe","outputId":"81c4bc97-b0a0-486f-8701-ac6927b84b01"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')\n","# %cd /content/drive/MyDrive/TRAINING"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"y4zyVrZvV-2I"},"outputs":[],"source":["# %%capture\n","# !pip install sentence_transformers"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"AkkomPGdV3dV"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\lw\\miniconda3\\envs\\masterarbeit_lwo\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["from sentence_transformers import SentenceTransformer, InputExample\n","from torch.utils.data import DataLoader\n","from sentence_transformers import models, losses, util\n","from tqdm import tqdm\n","import random\n","from sentence_transformers import evaluation\n","import json\n","import pandas as pd\n","from collections import Counter\n","import os\n","from sklearn.model_selection import train_test_split\n","from helpers import *\n","import numpy as np\n","from datetime import datetime\n","from sklearn.model_selection import KFold\n","from transformers import set_seed\n","set_seed(42)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"722fJkSlB-VR"},"outputs":[],"source":["def create_trainig_samples(pos_dev_samples,neg_pairs):\n","  dev_set_total =[]\n","  anchors = set([x[0] for x in pos_dev_samples])\n","  neg_dev_samples = [x for x in neg_pairs if x[0] in anchors]\n","  print(\"Creating Devset\")\n","  for anchor in tqdm(anchors):\n","    pos_pairs_filtered = [x[1] for x in pos_dev_samples if x[0]==anchor]\n","    neg_pairs_filtered = [x[1] for x in neg_dev_samples if x[0]==anchor]\n","    dev_set_total.append({\"query\":anchor,\"positive\":pos_pairs_filtered,\"negative\":neg_pairs_filtered})\n","  return dev_set_total"]},{"cell_type":"markdown","metadata":{"id":"xSp9eTjdnZWD"},"source":["# Variables"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3pcrar0nWJqC"},"outputs":[],"source":["modelname = \"../00_data/SBERT_Models/models/jobgbert_TSDAE_epochs5\"\n","# modelname = \"agne/jobgbert\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QEF97EZFt6LY"},"outputs":[],"source":["model = SentenceTransformer(modelname)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rNJLBve_WiNK"},"outputs":[],"source":["if modelname == \"agne/jobgbert\":\n","  TSDAE = \"woTSDAE\"\n","elif modelname == \"../00_data/SBERT_Models/models/jobgbert_TSDAE_epochs5\"\n","  TSDAE = \"wTSDAE\"\n","else:\n","  raise TypeError"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1681799404027,"user":{"displayName":"Lukas Wolfrum","userId":"10737638498661133063"},"user_tz":-120},"id":"c5g4imwtpy2z","outputId":"0fa97fe8-055b-462c-f42f-f7f39439dbb0"},"outputs":[],"source":["batch_size = 16\n","lr = 2e-5\n","num_epochs = 1\n","fold_size = 10\n","output_path = f\"../00_data/SBERT_Models/models/jobgbert_batch{batch_size}_{TSDAE}_{lr}_f{fold_size}\"\n","output_path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hWnxsnraA76J"},"outputs":[],"source":["kf = KFold(n_splits=fold_size, random_state=42, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ux1alEzQBIY4"},"outputs":[],"source":["MRR = []\n","MRR_AT = 100\n","training_start = \"\".join([c for c in str(datetime.now()).split('.')[0] if c.isdigit()])\n","max_MRR = 0\n","\n","for epoch, (train_index, dev_index) in enumerate(kf.split(pos_pairs)):\n","\n","  pos_train_samples = [pos_pairs[i] for i in train_index]\n","  pos_dev_samples = [pos_pairs[i] for i in dev_index]\n","  warmup = len(pos_train_samples)*0.1\n"," \n","  dev_set_total = create_trainig_samples(pos_dev_samples,neg_pairs)\n","  train_examples = []\n","  for item in pos_train_samples:\n","    train_examples.append(InputExample(texts=[item[0], item[1]]))\n","  train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=batch_size)\n","  train_loss = losses.MultipleNegativesRankingLoss(model)\n","  evaluator = evaluation.RerankingEvaluator(dev_set_total,mrr_at_k=100,show_progress_bar=True)\n","  # train the model \n","  \n","  model.fit(train_objectives=[(train_dataloader, train_loss)],\n","    epochs=num_epochs,\n","    warmup_steps=warmup,\n","    evaluator=evaluator,\n","    checkpoint_path=\"/content/modeltrain\",\n","    checkpoint_save_total_limit=1,\n","    #save_best_model = True,\n","    optimizer_params={'lr':lr},\n","    checkpoint_save_steps = 1000,\n","    output_path= output_path,\n","  )\n","  # load the test ads and encode them with the current model\n","  testads = pd.DataFrame(load_json(\"../00_data/EURES/eures_testads_final_short.json\"))\n","  encodings_short = model.encode(list(testads[\"short_texts\"]), show_progress_bar=True)\n","  testads[\"embeddings_short\"] = encodings_short.tolist()\n","  embeddings = encode_jobs(model)\n","\n","  # make evaluation\n","  similarities = {}\n","  for k in embeddings:\n","    similarities[k] = (util.cos_sim(testads[\"embeddings_short\"],embeddings[k][\"embeddings\"]))\n","  for k in similarities.keys():\n","    ranks = []\n","    missing = 0\n","    simdf = pd.DataFrame(similarities[k],columns=embeddings[k][\"esco_id\"], index=testads[\"esco_id\"])\n","    for i in tqdm(range(len(simdf))):\n","      id = simdf.iloc[i].name\n","      series = simdf.iloc[i].sort_values(ascending=False).reset_index()\n","      #print(series)\n","      rank = (series[series[\"index\"]==id].index.item()+1)\n","      #print(rank)\n","      if rank > MRR_AT:\n","        missing +=1\n","        ranks.append(0)\n","      else:\n","        ranks.append(1/rank)\n","    missing = missing/len(simdf)\n","    current_run = {\"model\":output_path.split(\"/\")[-1],\"epoch\":epoch,\n","                   \"embedding_kind\":k, \"MRR\":np.mean(ranks),\n","                   \"missing\":missing, \"MRR@\":MRR_AT,\n","                   \"training_details\":[training_start, batch_size, lr, warmup, num_epochs, fold_size, TSDAE]}\n","    MRR.append(current_run)\n","    df = pd.DataFrame(MRR)\n","    display(df)\n","    # safe model separately, if new model has higher MRR than best model before \n","    if np.mean(ranks) > max_MRR:\n","      print(f\"New best Model saved after epoch {epoch}\")\n","      max_MRR = np.mean(ranks)\n","      best_model_to_save = model\n","      best_model_to_save.save(f\"{output_path}_best\")\n","      write_json(f\"{output_path}/model_info.json\",current_run)\n","    df.to_excel(f\"{output_path}/eval/{training_start}_trainig_details.xlsx\")\n","best_model_to_save.save(f\"{output_path}\")"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPOVltfMm9syHPl4fxxi3lm","gpuClass":"premium","provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}
