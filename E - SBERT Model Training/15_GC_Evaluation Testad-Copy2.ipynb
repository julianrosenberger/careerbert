{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27060,
     "status": "ok",
     "timestamp": 1684238812705,
     "user": {
      "displayName": "Lukas Wolfrum",
      "userId": "10737638498661133063"
     },
     "user_tz": -120
    },
    "id": "0t74FaNzNYLh",
    "outputId": "cceade98-785a-432a-aee3-c829c1b41dfb"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# %cd /content/drive/MyDrive/TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 25781,
     "status": "ok",
     "timestamp": 1684238838479,
     "user": {
      "displayName": "Lukas Wolfrum",
      "userId": "10737638498661133063"
     },
     "user_tz": -120
    },
    "id": "xTK4iRKPNsmr"
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !pip install sentence_transformers\n",
    "# !pip install pypdf\n",
    "# !pip install xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11232,
     "status": "ok",
     "timestamp": 1684238849705,
     "user": {
      "displayName": "Lukas Wolfrum",
      "userId": "10737638498661133063"
     },
     "user_tz": -120
    },
    "id": "nSJ_xOTyNe79",
    "outputId": "1bf2344e-6aa9-4771-ac7d-dd4cce459371"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1144492/1460843178.py:3: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython.display\n",
      "  from IPython.core.display import display, HTML\n",
      "[nltk_data] Downloading package punkt to /home/roj14702/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from datetime import datetime\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import os\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "import pandas as pd\n",
    "from helpers import *\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from pypdf import PdfReader\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm \n",
    "from collections import Counter\n",
    "import math\n",
    "from nltk import word_tokenize\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer,pipeline\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hr-iUSpfKNxD"
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1684238849706,
     "user": {
      "displayName": "Lukas Wolfrum",
      "userId": "10737638498661133063"
     },
     "user_tz": -120
    },
    "id": "XfGrYGfhujsN"
   },
   "outputs": [],
   "source": [
    "def load_cvs():\n",
    "    cvs = []\n",
    "    for i in range(1,6):\n",
    "        cv = \"\"\n",
    "        reader = PdfReader(f\"../00_data/CVs/CV_{i}.pdf\")\n",
    "\n",
    "        pages = reader.pages\n",
    "        for i in range(len(pages)):\n",
    "            page = reader.pages[i].extract_text().strip()\n",
    "            cv +=page\n",
    "        cvs.append(cv)\n",
    "    return cvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1684238849706,
     "user": {
      "displayName": "Lukas Wolfrum",
      "userId": "10737638498661133063"
     },
     "user_tz": -120
    },
    "id": "l_8YywleOER5"
   },
   "outputs": [],
   "source": [
    "def load_pickle(filepath):\n",
    "  with open(filepath, \"rb\") as fIn:\n",
    "      stored_data = pickle.load(fIn)\n",
    "  return stored_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1684238849706,
     "user": {
      "displayName": "Lukas Wolfrum",
      "userId": "10737638498661133063"
     },
     "user_tz": -120
    },
    "id": "pSNVHdHjfJD4"
   },
   "outputs": [],
   "source": [
    "def setup_classifier():\n",
    "    path = \"../00_data/Classifier/model_classification_jobgbert/\"\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(path)\n",
    "    Classifier = pipeline(\"text-classification\",model,tokenizer=tokenizer)\n",
    "    return Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1684238849706,
     "user": {
      "displayName": "Lukas Wolfrum",
      "userId": "10737638498661133063"
     },
     "user_tz": -120
    },
    "id": "OQAUPoyf6ATh"
   },
   "outputs": [],
   "source": [
    "def ismanager(ad):\n",
    "  return \"leiter\" in ad[\"jobtitle\"].lower() or \"führungskraft\" in ad[\"jobtitle\"].lower() or \"arzt\" in ad[\"jobtitle\"].lower() #or ad[\"esco_id\"][0]==\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1684238849707,
     "user": {
      "displayName": "Lukas Wolfrum",
      "userId": "10737638498661133063"
     },
     "user_tz": -120
    },
    "id": "x0qpW7QPrJi3"
   },
   "outputs": [],
   "source": [
    "def text_alphanum(text):\n",
    "  return \"\".join(x for x in text if x.isalnum() or x.isspace())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1684238849707,
     "user": {
      "displayName": "Lukas Wolfrum",
      "userId": "10737638498661133063"
     },
     "user_tz": -120
    },
    "id": "EyDo7RmGejgJ"
   },
   "outputs": [],
   "source": [
    "def shorten_text(text,pipe):\n",
    "    annots_jobad = []\n",
    "    splitted_text = [x for x in text.split(\"\\n\") if x != \"\" or x != \" ,\"]\n",
    "    print(len(splitted_text))\n",
    "    if len(splitted_text) <= 2 or len(splitted_text)>50:\n",
    "      tokenized = word_tokenize(text, language=\"german\")\n",
    "      no_chunks = math.ceil(len(tokenized)/20)\n",
    "      print(no_chunks)\n",
    "      splitted_text = np.array_split((tokenized), no_chunks)\n",
    "      splitted_text = [\" \".join(x) for x in splitted_text]\n",
    "    #print(len(splitted_text))\n",
    "    for paragraph in splitted_text:\n",
    "        try:\n",
    "            res = pipe(paragraph)[0][\"label\"]\n",
    "        except:\n",
    "            res = pipe(paragraph[:250])[0][\"label\"]\n",
    "        annots_jobad.append({\"text\":paragraph,\"label\":res})\n",
    "        text_short = \" \".join([x[\"text\"] for x in annots_jobad if x[\"label\"] == \"LABEL_1\"])\n",
    "    return text_short"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFcGnT6HNw_6"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1684238849707,
     "user": {
      "displayName": "Lukas Wolfrum",
      "userId": "10737638498661133063"
     },
     "user_tz": -120
    },
    "id": "DaOu-ijuguxF"
   },
   "outputs": [],
   "source": [
    "prefix_path = \"../00_data/SBERT_Models/models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 2104,
     "status": "ok",
     "timestamp": 1684238851805,
     "user": {
      "displayName": "Lukas Wolfrum",
      "userId": "10737638498661133063"
     },
     "user_tz": -120
    },
    "id": "OBXlTG72NwQS"
   },
   "outputs": [],
   "source": [
    "testads = pd.DataFrame(load_json(r\"../00_data/EURES/eures_testads_final_short.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W82kJ5OiOGFc"
   },
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1684238851807,
     "user": {
      "displayName": "Lukas Wolfrum",
      "userId": "10737638498661133063"
     },
     "user_tz": -120
    },
    "id": "QE5A4LArONyu",
    "outputId": "21864e40-1b76-4e6e-b0f2-879d4e9031f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available model: gbert_batch32_woTSDAE_2e-05_f10\n",
      "Available model: gbert_batch16_wTSDAE_2e-05_f10_best\n",
      "Available model: jobgbert_TSDAE_epochs5\n",
      "Available model: jobgbert_batch32_woTSDAE_2e-05_f10\n",
      "Available model: gbert_TSDAE_epochs5\n",
      "Available model: gbert_batch16_wTSDAE_2e-05_f10\n"
     ]
    }
   ],
   "source": [
    "for model in os.listdir(prefix_path):\n",
    "  print(f\"Available model: {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1684238851807,
     "user": {
      "displayName": "Lukas Wolfrum",
      "userId": "10737638498661133063"
     },
     "user_tz": -120
    },
    "id": "qLSNgcfJf5M2"
   },
   "outputs": [],
   "source": [
    "paths = [#\"deepset/gbert-base\",\n",
    "          #\"agne/jobGBERT\",\n",
    "          #\"jobgbert_TSDAE_epochs5/\",\n",
    "          #\"gbert_TSDAE_epochs5/\",\n",
    "          #\"jobgbert_batch16_woTSDAE_2e-05_f10/\",\n",
    "          #\"jobgbert_batch16_wTSDAE_2e-05_f10/\",\n",
    "          \"jobgbert_batch32_woTSDAE_2e-05_f10/\",\n",
    "          #\"jobgbert_batch32_wTSDAE_2e-05_f10/\",\n",
    "          #\"jobgbert_batch64_woTSDAE_2e-05_f10/\",\n",
    "          #\"jobgbert_batch64_wTSDAE_2e-05_f10/\",\n",
    "          #\"gbert_batch16_woTSDAE_2e-05_f10/\",\n",
    "          #\"gbert_batch16_wTSDAE_2e-05_f10/\",\n",
    "          \"gbert_batch32_woTSDAE_2e-05_f10/\",\n",
    "         # \"gbert_batch32_wTSDAE_2e-05_f10/\",\n",
    "          #\"gbert_batch64_woTSDAE_2e-05_f10/\",\n",
    "          #\"gbert_batch64_wTSDAE_2e-05_f10/\",\n",
    "          ]\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CZ9-7M1Dj_rS"
   },
   "source": [
    "# Evaluate with Test Ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1684238851808,
     "user": {
      "displayName": "Lukas Wolfrum",
      "userId": "10737638498661133063"
     },
     "user_tz": -120
    },
    "id": "cbQmmDTzfEvS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model jobgbert_batch32_woTSDAE_2e-05_f10/\n",
      "dict_keys(['skillsets', 'desc', 'jobtitle', 'adcentroid_filtered', 'adcentroid_unfiltered', 'job_centroid'])\n",
      "Creating Embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc402152e19848a6b3320d70232f083c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating Embeddings. Evaluating.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roj14702/miniconda3/envs/careerbert/lib/python3.10/site-packages/sentence_transformers/util.py:44: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  a = torch.tensor(a)\n",
      "100%|███████████████████████████████████████████████████████| 2250/2250 [00:01<00:00, 1351.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>textkind</th>\n",
       "      <th>embedding_kind</th>\n",
       "      <th>MRR</th>\n",
       "      <th>missing</th>\n",
       "      <th>max_similarity</th>\n",
       "      <th>MRR@</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jobgbert_batch32_woTSDAE_2e-05_f10</td>\n",
       "      <td>embeddings_short</td>\n",
       "      <td>job_centroid</td>\n",
       "      <td>0.433598</td>\n",
       "      <td>0.105778</td>\n",
       "      <td>tensor(0.9398)</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                model          textkind embedding_kind  \\\n",
       "0  jobgbert_batch32_woTSDAE_2e-05_f10  embeddings_short   job_centroid   \n",
       "\n",
       "        MRR   missing  max_similarity  MRR@  \n",
       "0  0.433598  0.105778  tensor(0.9398)   100  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model gbert_batch32_woTSDAE_2e-05_f10/\n",
      "dict_keys(['skillsets', 'desc', 'adcentroid_filtered', 'adcentroid_unfiltered', 'job_centroid'])\n",
      "Creating Embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f69ba45d30da42c0938f77b5856308d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/71 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating Embeddings. Evaluating.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 2250/2250 [00:01<00:00, 1261.36it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>textkind</th>\n",
       "      <th>embedding_kind</th>\n",
       "      <th>MRR</th>\n",
       "      <th>missing</th>\n",
       "      <th>max_similarity</th>\n",
       "      <th>MRR@</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jobgbert_batch32_woTSDAE_2e-05_f10</td>\n",
       "      <td>embeddings_short</td>\n",
       "      <td>job_centroid</td>\n",
       "      <td>0.433598</td>\n",
       "      <td>0.105778</td>\n",
       "      <td>tensor(0.9398)</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gbert_batch32_woTSDAE_2e-05_f10</td>\n",
       "      <td>embeddings_short</td>\n",
       "      <td>job_centroid</td>\n",
       "      <td>0.414569</td>\n",
       "      <td>0.123111</td>\n",
       "      <td>tensor(0.9497)</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                model          textkind embedding_kind  \\\n",
       "0  jobgbert_batch32_woTSDAE_2e-05_f10  embeddings_short   job_centroid   \n",
       "1     gbert_batch32_woTSDAE_2e-05_f10  embeddings_short   job_centroid   \n",
       "\n",
       "        MRR   missing  max_similarity  MRR@  \n",
       "0  0.433598  0.105778  tensor(0.9398)   100  \n",
       "1  0.414569  0.123111  tensor(0.9497)   100  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MRR = []\n",
    "MRR_AT = 100\n",
    "currently = \"\".join([c for c in str(datetime.now()).split('.')[0] if c.isdigit()])\n",
    "\n",
    "for model_path in paths:\n",
    "  print(f\"Loading Model {model_path}\")\n",
    "  if model_path in [\"agne/jobGBERT\",\"deepset/gbert-base\"]:\n",
    "    model = SentenceTransformer(model_path)\n",
    "    embeddings = encode_jobs(model)\n",
    "  else:\n",
    "    model = SentenceTransformer(f\"../00_data/SBERT_Models/models/{model_path}\")\n",
    "    embeddings = load_pickle(f\"../00_data/SBERT_Models/models/{model_path}embeddings.pkl\")\n",
    "  print(embeddings.keys())\n",
    "  print(\"Creating Embeddings.\")\n",
    "  encodings_short = model.encode(list(testads[\"short_texts\"]), show_progress_bar=True)\n",
    " # encodings_long = model.encode(list(testads[\"description\"]), show_progress_bar=True) \n",
    "\n",
    "  testads[\"embeddings_short\"] = encodings_short.tolist()\n",
    "  #testads[\"embeddings_long\"] = encodings_long.tolist()\n",
    "\n",
    "  print(\"Finished creating Embeddings. Evaluating.\")\n",
    "\n",
    "  for textkind in [\"embeddings_short\"]:#,\"embeddings_long\"]:\n",
    "    similarities = {}\n",
    "    for k in [\"job_centroid\"]:\n",
    "      similarities[k] = (util.cos_sim(testads[textkind],embeddings[k][\"embeddings\"]))\n",
    "    \n",
    "    for k in similarities:\n",
    "      ranks = []\n",
    "      missing = 0\n",
    "      max_similarity = (max(map(max, similarities[k])))\n",
    "      simdf = pd.DataFrame(similarities[k],columns=embeddings[k][\"esco_id\"], index=testads[\"esco_id\"])\n",
    "      for i in tqdm(range(len(simdf))):\n",
    "        id = simdf.iloc[i].name\n",
    "        series = simdf.iloc[i].sort_values(ascending=False).reset_index()\n",
    "        #print(series)\n",
    "        rank = (series[series[\"index\"]==id].index.item()+1)\n",
    "        #print(rank)\n",
    "        if rank > MRR_AT:\n",
    "          missing +=1\n",
    "          ranks.append(0)\n",
    "        else:\n",
    "          ranks.append(1/rank)\n",
    "      missing = missing/len(simdf)\n",
    "      MRR.append({\"model\":model_path.split(\"/\")[-2],\"textkind\": textkind,\"embedding_kind\":k,\n",
    "                  \"MRR\":np.mean(ranks), \"missing\":missing, \"max_similarity\": max_similarity, \"MRR@\":MRR_AT})\n",
    "      df = pd.DataFrame(MRR).sort_values(by=[\"MRR\"], ascending=[False]).reset_index(drop=True)\n",
    "      display(df)\n",
    "      df.to_excel(f\"../00_data/SBERT_Models/evaluation/{currently}_evaluation.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1684238851809,
     "user": {
      "displayName": "Lukas Wolfrum",
      "userId": "10737638498661133063"
     },
     "user_tz": -120
    },
    "id": "VJtJH5_--s8x"
   },
   "outputs": [],
   "source": [
    "# df = pd.read_excel(f\"/content/drive/MyDrive/TRAINING/_COSINESIM/20230403173019_evaluation.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       Stellenangebotsbeschreibung: Willkommen im Tea...\n",
      "1       Stellenangebotsbeschreibung: Umweltingenieurin...\n",
      "2       Stellenangebotsbeschreibung: Im Umwelt- und Na...\n",
      "3       Stellenangebotsbeschreibung: Sie suchen einen ...\n",
      "4       Stellenangebotsbeschreibung: - Proaktive Betre...\n",
      "                              ...                        \n",
      "2245    Stellenangebotsbeschreibung: Inhouse Consultan...\n",
      "2246    Stellenangebotsbeschreibung: Bei einem unserer...\n",
      "2247    Stellenangebotsbeschreibung: Menschen und Tech...\n",
      "2248    Stellenangebotsbeschreibung: Die Wasserstraßen...\n",
      "2249    Stellenangebotsbeschreibung: Für den Fachberei...\n",
      "Name: description, Length: 2250, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(testads['description'])\n",
    "# print(testads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Dict, Tuple\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Config\n",
    "client = OpenAI()\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "MRR_AT = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"Load EURES test ads and ESCO jobs\"\"\"\n",
    "    # Load test ads\n",
    "    testads = pd.DataFrame(load_json(\"../00_data/EURES/eures_testads_final_short.json\"))\n",
    "    \n",
    "    # Load ESCO jobs (adjust path as needed)\n",
    "    with open(\"../00_data/ESCO/ESCO_JOBS_ALL.json\", 'r') as f:\n",
    "        esco_jobs = json.load(f)\n",
    "    \n",
    "    return testads, esco_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_matching_prompt(description: str, esco_jobs: List[Dict]) -> str:\n",
    "    \"\"\"Generate and return the prompt for job matching\"\"\"\n",
    "    prompt = f\"\"\"Given this job description, identify EXACTLY 20 most likely matching ESCO occupation IDs.\n",
    "    Consider the job responsibilities, required skills, and overall role.\n",
    "\n",
    "    Job Description:\n",
    "    {description}\n",
    "\n",
    "    Available ESCO Jobs:\n",
    "    {json.dumps([{\n",
    "        'id': job['jobid_esco'],\n",
    "        'title': job['jobtitle'],\n",
    "        'description': job['jobdescription']\n",
    "    } for job in esco_jobs], ensure_ascii=False)}\n",
    "\n",
    "    IMPORTANT: You must return EXACTLY 20 matches, ranked by relevance.\n",
    "    Return your response in this JSON format:\n",
    "    {{\n",
    "        \"matches\": [\n",
    "            {{\n",
    "                \"esco_id\": \"id\",\n",
    "                \"confidence\": score_0_to_100,\n",
    "                \"reasoning\": \"brief explanation\"\n",
    "            }}\n",
    "        ]\n",
    "    }}\n",
    "    \n",
    "    List matches in descending order of confidence, with exactly 20 matches.\"\"\"\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_prompt(description: str, esco_jobs: List[Dict]):\n",
    "    \"\"\"Print the full prompt that will be sent to the API\"\"\"\n",
    "    prompt = generate_matching_prompt(description, esco_jobs)\n",
    "    print(\"=== System Message ===\")\n",
    "    print(\"You are a job matching expert. Always return exactly 20 matches.\\n\")\n",
    "    print(\"=== User Message ===\")\n",
    "    print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_job(description: str, esco_jobs: List[Dict], verbose: bool = False) -> List[Dict]:\n",
    "    \"\"\"Match a single job description to ESCO jobs\"\"\"\n",
    "    prompt = generate_matching_prompt(description, esco_jobs)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\n=== Using Prompt ===\")\n",
    "        preview_prompt(description, esco_jobs)\n",
    "        print(\"\\n=== Sending Request to API ===\")\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a job matching expert. Always return exactly 20 matches.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"\\n=== API Response ===\")\n",
    "            print(response.choices[0].message.content)\n",
    "        \n",
    "        result = json.loads(response.choices[0].message.content)\n",
    "        matches = result['matches']\n",
    "        \n",
    "        # Verify we got exactly 20 matches\n",
    "        if len(matches) != 20:\n",
    "            print(f\"Warning: Got {len(matches)} matches instead of 20\")\n",
    "            # Pad with dummy matches if necessary\n",
    "            while len(matches) < 20:\n",
    "                matches.append({\n",
    "                    \"esco_id\": \"0\",\n",
    "                    \"confidence\": 0,\n",
    "                    \"reasoning\": \"Padding match\"\n",
    "                })\n",
    "            # Trim if we somehow got more\n",
    "            matches = matches[:20]\n",
    "            \n",
    "        return matches\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in matching: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prompt_generation():\n",
    "    \"\"\"Test the prompt generation with a sample job\"\"\"\n",
    "    print(\"Testing prompt generation with first test job...\")\n",
    "    \n",
    "    # Load test data\n",
    "    testads, esco_jobs = load_data()\n",
    "    \n",
    "    # Get first job description\n",
    "    first_job = testads.iloc[0]\n",
    "    \n",
    "    # Preview the prompt\n",
    "    print(\"\\nPrompt Preview for First Job:\")\n",
    "    preview_prompt(first_job['description'], esco_jobs)\n",
    "    \n",
    "    return first_job, esco_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first_job, esco_jobs = test_prompt_generation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_single_match():\n",
    "    \"\"\"Test a single job match with full output\"\"\"\n",
    "    first_job, esco_jobs = test_prompt_generation()\n",
    "    \n",
    "    print(\"\\nTesting job matching with verbose output...\")\n",
    "    matches = match_job(first_job['description'], esco_jobs, verbose=True)\n",
    "    \n",
    "    print(\"\\nMatching Results:\")\n",
    "    for i, match in enumerate(matches, 1):\n",
    "        print(f\"\\n{i}. ESCO ID: {match['esco_id']}\")\n",
    "        print(f\"   Confidence: {match['confidence']}\")\n",
    "        print(f\"   Reasoning: {match['reasoning']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_single_match()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_match(matches: List[Dict], true_esco_id: str) -> Dict:\n",
    "    \"\"\"Evaluate a single job match\"\"\"\n",
    "    # Find rank of correct ESCO ID\n",
    "    correct_rank = None\n",
    "    for rank, match in enumerate(matches, 1):\n",
    "        if match['esco_id'] == true_esco_id:\n",
    "            correct_rank = rank\n",
    "            break\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mrr = 1/correct_rank if correct_rank and correct_rank <= MRR_AT else 0\n",
    "    missing = 1 if not correct_rank or correct_rank > MRR_AT else 0\n",
    "    \n",
    "    return {\n",
    "        'correct_rank': correct_rank,\n",
    "        'mrr': mrr,\n",
    "        'missing': missing,\n",
    "        'top_1_hit': correct_rank == 1,\n",
    "        'top_5_hit': correct_rank is not None and correct_rank <= 5,\n",
    "        'top_20_hit': correct_rank is not None and correct_rank <= 20,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_jobs(testads: pd.DataFrame, esco_jobs: List[Dict], batch_size: int = 5):\n",
    "    \"\"\"Process all jobs and evaluate results\"\"\"\n",
    "    MRR = []\n",
    "    currently = \"\".join([c for c in str(datetime.now()).split('.')[0] if c.isdigit()])\n",
    "    \n",
    "    for i in tqdm(range(0, len(testads), batch_size)):\n",
    "        batch = testads.iloc[i:i+batch_size]\n",
    "        \n",
    "        for _, job in batch.iterrows():\n",
    "            # Get matches for this job\n",
    "            matches = match_job(job['description'], esco_jobs)\n",
    "            \n",
    "            if not matches:  # Skip if matching failed\n",
    "                continue\n",
    "                \n",
    "            # Evaluate matches\n",
    "            evaluation = evaluate_match(matches, job['esco_id'])\n",
    "            \n",
    "            MRR.append({\n",
    "                \"model\": MODEL,\n",
    "                \"job_id\": job.name,\n",
    "                \"esco_id\": job['esco_id'],\n",
    "                \"MRR\": evaluation['mrr'],\n",
    "                \"missing\": evaluation['missing'],\n",
    "                \"rank\": evaluation['correct_rank'],\n",
    "                \"MRR@\": MRR_AT,\n",
    "                \"top_20_hit\": evaluation['top_20_hit']\n",
    "            })\n",
    "            \n",
    "            # Display running results\n",
    "            df = pd.DataFrame(MRR)\n",
    "            summary = {\n",
    "                \"Mean MRR\": df['MRR'].mean(),\n",
    "                \"Missing Rate\": df['missing'].mean(),\n",
    "                \"Top-20 Hit Rate\": df['top_20_hit'].mean(),\n",
    "                \"Processed Jobs\": len(df)\n",
    "            }\n",
    "            display(pd.DataFrame([summary]))\n",
    "            \n",
    "            # Save results\n",
    "            df.to_excel(f\"../00_data/LLM_evaluation/{currently}_evaluation.xlsx\")\n",
    "        \n",
    "        # Respect API rate limits\n",
    "        time.sleep(1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m testads, esco_jobs \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Process a small batch first to test\u001b[39;00m\n\u001b[1;32m      5\u001b[0m test_batch \u001b[38;5;241m=\u001b[39m testads\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m3\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load EURES test ads and ESCO jobs\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load test ads\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m testads \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame(load_json(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../00_data/EURES/eures_testads_final_short.json\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Load ESCO jobs (adjust path as needed)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../00_data/ESCO/ESCO_JOBS_ALL.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "testads, esco_jobs = load_data()\n",
    "\n",
    "# Process a small batch first to test\n",
    "test_batch = testads.head(3)\n",
    "print(\"Running initial test with 3 jobs...\")\n",
    "test_results = process_jobs(test_batch, esco_jobs)\n",
    "\n",
    "# If test successful, process all jobs\n",
    "if input(\"Continue with full evaluation? (y/n): \").lower() == 'y':\n",
    "    results_df = process_jobs(testads, esco_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batch_prompt(description: str, batch: List[Dict], batch_num: int, total_batches: int) -> str:\n",
    "    \"\"\"Create prompt for batch processing with stricter matching criteria\"\"\"\n",
    "    return \"\"\"Analysieren Sie diese Stellenbeschreibung und vergleichen Sie sie mit den ESCO-Berufen.\n",
    "    Finden Sie nur EXAKTE Übereinstimmungen, keine verwandten oder ähnlichen Berufe.\n",
    "\n",
    "    Stellenbeschreibung:\n",
    "    {}\n",
    "\n",
    "    ESCO-Berufe Batch {}/{}:\n",
    "    {}\n",
    "\n",
    "    Bewertungsrichtlinien:\n",
    "    - Bewerten Sie die Ähnlichkeit streng mathematisch (wie ein Cosinus-Similarity-Score)\n",
    "    - 90-100: Fast identische Beschreibung\n",
    "    - 70-89: Sehr hohe Überlappung der Kernaufgaben\n",
    "    - 50-69: Mittlere Überlappung\n",
    "    - 30-49: Geringe Überlappung\n",
    "    - 0-29: Minimale oder keine Überlappung\n",
    "\n",
    "    Geben Sie nur Matches zurück, die eine echte inhaltliche Übereinstimmung aufweisen.\n",
    "    Format (JSON):\n",
    "    {{\n",
    "        \"matches\": [\n",
    "            {{\n",
    "                \"esco_id\": \"id\",\n",
    "                \"confidence\": similarity_score,\n",
    "                \"reasoning\": \"kurze_begruendung_der_uebereinstimmung\"\n",
    "            }}\n",
    "        ]\n",
    "    }}\"\"\".format(\n",
    "        description,\n",
    "        batch_num,\n",
    "        total_batches,\n",
    "        json.dumps([{\n",
    "            'id': job['jobid_esco'],\n",
    "            'title': job['jobtitle'],\n",
    "            'description': job['jobdescription'][:200],\n",
    "            'skills': job['skills'][:5]  # Include top 5 skills for better matching\n",
    "        } for job in batch], ensure_ascii=False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ranking_prompt(description: str, matches: List[Dict]) -> str:\n",
    "    \"\"\"Create prompt for final ranking with strict comparison criteria\"\"\"\n",
    "    return \"\"\"Erstellen Sie ein finales Ranking der relevantesten Jobmatches.\n",
    "    \n",
    "    WICHTIG: Ranken Sie die Jobs streng nach textueller Ähnlichkeit, wie bei einem Embedding-Vergleich.\n",
    "    Verwenden Sie die bereits berechneten Confidence-Scores als Basis und verfeinern Sie diese.\n",
    "\n",
    "    Stellenbeschreibung:\n",
    "    {}\n",
    "\n",
    "    Potentielle Matches ({} verfügbar):\n",
    "    {}\n",
    "\n",
    "    Kriterien für das Ranking:\n",
    "    1. Textuelle Ähnlichkeit der Jobbeschreibungen\n",
    "    2. Übereinstimmung der Kernaufgaben\n",
    "    3. Übereinstimmung der erforderlichen Fähigkeiten\n",
    "\n",
    "    Format (JSON):\n",
    "    {{\n",
    "        \"matches\": [\n",
    "            {{\n",
    "                \"esco_id\": \"id\",\n",
    "                \"confidence\": similarity_score,\n",
    "                \"reasoning\": \"kurze_begruendung\"\n",
    "            }}\n",
    "        ]\n",
    "    }}\n",
    "    \n",
    "    Geben Sie alle verfügbaren Matches zurück, streng nach Ähnlichkeit sortiert.\"\"\".format(\n",
    "        description,\n",
    "        len(matches),\n",
    "        json.dumps(matches, ensure_ascii=False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_matches(matches: List[Dict], expected_count: int = 100) -> List[Dict]:\n",
    "    \"\"\"Process matches to ensure consistent scoring and ranking\"\"\"\n",
    "    # Sort by confidence\n",
    "    sorted_matches = sorted(matches, key=lambda x: float(x['confidence']), reverse=True)\n",
    "    \n",
    "    # Normalize confidence scores to better spread across range\n",
    "    if sorted_matches:\n",
    "        max_conf = float(sorted_matches[0]['confidence'])\n",
    "        min_conf = float(sorted_matches[-1]['confidence'])\n",
    "        conf_range = max_conf - min_conf if max_conf != min_conf else 1\n",
    "        \n",
    "        for match in sorted_matches:\n",
    "            # Normalize and rescale confidence to [0, 100]\n",
    "            orig_conf = float(match['confidence'])\n",
    "            norm_conf = (orig_conf - min_conf) / conf_range * 100\n",
    "            match['confidence'] = round(norm_conf, 2)\n",
    "    \n",
    "    return sorted_matches[:expected_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_job_batched(description: str, esco_jobs: List[Dict], batch_size: int = 50, verbose: bool = False) -> List[Dict]:\n",
    "    \"\"\"Match jobs by processing ESCO jobs in batches and combining results\"\"\"\n",
    "    all_matches = []\n",
    "    total_batches = (len(esco_jobs) + batch_size - 1) // batch_size\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Processing {total_batches} batches of ESCO jobs...\")\n",
    "    \n",
    "    # Process ESCO jobs in batches\n",
    "    for i in range(0, len(esco_jobs), batch_size):\n",
    "        batch = esco_jobs[i:i+batch_size]\n",
    "        batch_num = i//batch_size + 1\n",
    "        \n",
    "        prompt = create_batch_prompt(description, batch, batch_num, total_batches)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"\\nVerarbeite Batch {batch_num}/{total_batches}\")\n",
    "        \n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=MODEL,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"Sie sind ein Experte für Jobmatching und analysieren Stellenbeschreibungen in deutscher Sprache. Antworten Sie ausschließlich mit JSON.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0,\n",
    "                response_format={\"type\": \"json_object\"}\n",
    "            )\n",
    "            \n",
    "            batch_matches = json.loads(response.choices[0].message.content)['matches']\n",
    "            if verbose:\n",
    "                print(f\"Gefunden: {len(batch_matches)} Matches in diesem Batch\")\n",
    "            all_matches.extend(batch_matches)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Fehler bei Batch {batch_num}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Final ranking with improved processing\n",
    "    if len(all_matches) > 0:\n",
    "        if verbose:\n",
    "            print(f\"\\nErstelle finales Ranking aus {len(all_matches)} potentiellen Matches...\")\n",
    "        \n",
    "        # First process and normalize all matches\n",
    "        processed_matches = process_matches(all_matches)\n",
    "        \n",
    "        ranking_prompt = create_ranking_prompt(description, processed_matches)\n",
    "\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=MODEL,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"Sie sind ein Experte für semantische Textvergleiche und Jobmatching.\"},\n",
    "                    {\"role\": \"user\", \"content\": ranking_prompt}\n",
    "                ],\n",
    "                temperature=0,\n",
    "                response_format={\"type\": \"json_object\"}\n",
    "            )\n",
    "            \n",
    "            final_matches = json.loads(response.choices[0].message.content)['matches']\n",
    "            \n",
    "            # Process final matches again to ensure consistency\n",
    "            final_matches = process_matches(final_matches, min(len(all_matches), 100))\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"Finales Ranking enthält {len(final_matches)} Matches\")\n",
    "            \n",
    "            return final_matches\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim finalen Ranking: {e}\")\n",
    "            # Fallback to processed matches\n",
    "            return processed_matches\n",
    "    \n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_match(matches: List[Dict], true_esco_id: str) -> Dict:\n",
    "    \"\"\"Evaluate a single job match\"\"\"\n",
    "    # Find rank of correct ESCO ID\n",
    "    correct_rank = None\n",
    "    for rank, match in enumerate(matches, 1):\n",
    "        if match['esco_id'] == true_esco_id:\n",
    "            correct_rank = rank\n",
    "            break\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mrr = 1/correct_rank if correct_rank and correct_rank <= MRR_AT else 0\n",
    "    missing = 1 if not correct_rank or correct_rank > MRR_AT else 0\n",
    "    \n",
    "    return {\n",
    "        'correct_rank': correct_rank,\n",
    "        'mrr': mrr,\n",
    "        'missing': missing,\n",
    "        'top_1_hit': correct_rank == 1,\n",
    "        'top_5_hit': correct_rank is not None and correct_rank <= 5,\n",
    "        'top_20_hit': correct_rank is not None and correct_rank <= 20,\n",
    "        'top_100_hit': correct_rank is not None and correct_rank <= 100\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_jobs(testads: pd.DataFrame, esco_jobs: List[Dict], batch_size: int = 50):\n",
    "    \"\"\"Process all jobs using batched matching\"\"\"\n",
    "    MRR = []\n",
    "    currently = \"\".join([c for c in str(datetime.now()).split('.')[0] if c.isdigit()])\n",
    "    \n",
    "    for idx in tqdm(range(len(testads))):\n",
    "        job = testads.iloc[idx]\n",
    "        \n",
    "        # Get matches using batched approach\n",
    "        matches = match_job_batched(\n",
    "            job['description'], \n",
    "            esco_jobs, \n",
    "            batch_size=batch_size,\n",
    "            verbose=(idx == 0)  # Show verbose output for first job only\n",
    "        )\n",
    "        \n",
    "        if not matches:\n",
    "            continue\n",
    "            \n",
    "        evaluation = evaluate_match(matches, job['esco_id'])\n",
    "        \n",
    "        MRR.append({\n",
    "            \"model\": MODEL,\n",
    "            \"job_id\": job.name,\n",
    "            \"esco_id\": job['esco_id'],\n",
    "            \"MRR\": evaluation['mrr'],\n",
    "            \"missing\": evaluation['missing'],\n",
    "            \"rank\": evaluation['correct_rank'],\n",
    "            \"MRR@\": MRR_AT,\n",
    "            \"top_20_hit\": evaluation['top_20_hit'],\n",
    "            \"top_100_hit\": evaluation['top_100_hit']\n",
    "        })\n",
    "        \n",
    "        # Display running results\n",
    "        df = pd.DataFrame(MRR)\n",
    "        summary = {\n",
    "            \"Mean MRR\": df['MRR'].mean(),\n",
    "            \"Missing Rate\": df['missing'].mean(),\n",
    "            \"Top-20 Hit Rate\": df['top_20_hit'].mean(),\n",
    "            \"Top-100 Hit Rate\": df['top_100_hit'].mean(),\n",
    "            \"Processed Jobs\": len(df)\n",
    "        }\n",
    "        display(pd.DataFrame([summary]))\n",
    "        \n",
    "        df.to_excel(f\"../00_data/LLM_evaluation/{currently}_evaluation.xlsx\")\n",
    "        time.sleep(1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_single_job():\n",
    "    \"\"\"Test the matching system with a single job\"\"\"\n",
    "    # Load data\n",
    "    testads, esco_jobs = load_data()\n",
    "    \n",
    "    # Get first job\n",
    "    first_job = testads.iloc[0]\n",
    "    \n",
    "    print(\"Testing job matching with first job...\")\n",
    "    matches = match_job_batched(first_job['description'], esco_jobs, batch_size=50, verbose=True)\n",
    "    \n",
    "    print(\"\\nMatching Results:\")\n",
    "    for i, match in enumerate(matches[:10], 1):  # Show top 10 matches\n",
    "        print(f\"\\n{i}. ESCO ID: {match['esco_id']}\")\n",
    "        print(f\"   Confidence: {match['confidence']}\")\n",
    "        print(f\"   Reasoning: {match['reasoning']}\")\n",
    "    \n",
    "    # Evaluate the match\n",
    "    evaluation = evaluate_match(matches, first_job['esco_id'])\n",
    "    print(\"\\nEvaluation:\")\n",
    "    for metric, value in evaluation.items():\n",
    "        print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing job matching with first job...\n",
      "Processing 59 batches of ESCO jobs...\n",
      "\n",
      "Verarbeite Batch 1/59\n",
      "Gefunden: 1 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 2/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 3/59\n",
      "Gefunden: 2 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 4/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 5/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 6/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 7/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 8/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 9/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 10/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 11/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 12/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 13/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 14/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 15/59\n",
      "Gefunden: 3 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 16/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 17/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 18/59\n",
      "Gefunden: 1 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 19/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 20/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 21/59\n",
      "Gefunden: 1 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 22/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 23/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 24/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 25/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 26/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 27/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 28/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 29/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 30/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 31/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 32/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 33/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 34/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 35/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 36/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 37/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 38/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 39/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 40/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 41/59\n",
      "Gefunden: 3 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 42/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 43/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 44/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 45/59\n",
      "Gefunden: 2 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 46/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 47/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 48/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 49/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 50/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 51/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 52/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 53/59\n",
      "Gefunden: 2 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 54/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 55/59\n",
      "Gefunden: 5 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 56/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 57/59\n",
      "Gefunden: 2 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 58/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Verarbeite Batch 59/59\n",
      "Gefunden: 0 Matches in diesem Batch\n",
      "\n",
      "Erstelle finales Ranking aus 22 potentiellen Matches...\n",
      "Finales Ranking enthält 22 Matches\n",
      "\n",
      "Matching Results:\n",
      "\n",
      "1. ESCO ID: 1349.12\n",
      "   Confidence: 100.0\n",
      "   Reasoning: Die Stellenbeschreibung und der ESCO-Beruf Energiemanager/Energiemanagerin teilen den Fokus auf Nachhaltigkeit und Energiewende sowie die Koordination von Energieverbrauch und -management.\n",
      "\n",
      "2. ESCO ID: 2141.3\n",
      "   Confidence: 100.0\n",
      "   Reasoning: Die Stellenbeschreibung erfordert Kenntnisse im Bereich Wirtschaftsingenieurwesen, was direkt mit dem ESCO-Beruf des Wirtschaftsingenieurs übereinstimmt.\n",
      "\n",
      "3. ESCO ID: 3312.5\n",
      "   Confidence: 100.0\n",
      "   Reasoning: Die Stellenbeschreibung umfasst Aufgaben im Bereich der Export- und Handelsfinanzierung, die eng mit den Tätigkeiten eines Kreditsachbearbeiters verbunden sind, insbesondere in der Bewertung und Umsetzung von Finanzierungsanträgen.\n",
      "\n",
      "4. ESCO ID: 3312.6\n",
      "   Confidence: 100.0\n",
      "   Reasoning: Die Aufgaben in der Stellenbeschreibung beinhalten die Prüfung und Koordination von Kreditverträgen, was direkt mit den Tätigkeiten eines Underwriters im Kreditwesen übereinstimmt.\n",
      "\n",
      "5. ESCO ID: 2412.10\n",
      "   Confidence: 100.0\n",
      "   Reasoning: Die Stellenbeschreibung beinhaltet Aspekte der Risikoanalyse und der finanziellen Absicherung, die stark mit den Aufgaben eines Risikomanagers übereinstimmen.\n",
      "\n",
      "6. ESCO ID: 2412.2\n",
      "   Confidence: 100.0\n",
      "   Reasoning: Die Position erfordert Kenntnisse in der Finanzberatung und der Strukturierung von Finanzierungsmodellen, was direkt mit den Aufgaben eines Geschäftskundenberaters übereinstimmt.\n",
      "\n",
      "7. ESCO ID: 1211.1.1\n",
      "   Confidence: 100.0\n",
      "   Reasoning: Die Stellenbeschreibung erfordert Kenntnisse in der Exportfinanzierung und der Koordination von Finanzierungsprozessen, was direkt mit den Aufgaben eines Bankangestellten übereinstimmt.\n",
      "\n",
      "8. ESCO ID: 1211.1.2\n",
      "   Confidence: 100.0\n",
      "   Reasoning: Die Position erfordert umfassende Kenntnisse im Finanzmanagement und der Strukturierung von Krediten, was den Aufgaben eines Bankangestellten entspricht.\n",
      "\n",
      "9. ESCO ID: 1324.3.2.2\n",
      "   Confidence: 100.0\n",
      "   Reasoning: Die Stellenbeschreibung und der ESCO-Beruf beziehen sich beide auf die Strukturierung und Umsetzung von Exportfinanzierungen, insbesondere im Bereich nachhaltiger Projekte.\n",
      "\n",
      "10. ESCO ID: 1324.3.2.16\n",
      "   Confidence: 100.0\n",
      "   Reasoning: Beide Positionen erfordern Kenntnisse in der Exportfinanzierung und der Einhaltung von Vorschriften, insbesondere im internationalen Handel.\n",
      "\n",
      "Evaluation:\n",
      "correct_rank: None\n",
      "mrr: 0\n",
      "missing: 1\n",
      "top_1_hit: False\n",
      "top_5_hit: False\n",
      "top_20_hit: False\n",
      "top_100_hit: False\n"
     ]
    }
   ],
   "source": [
    "test_single_job()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JzJ1EhBMewWJ"
   },
   "source": [
    "# Test with TFIDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1684238851809,
     "user": {
      "displayName": "Lukas Wolfrum",
      "userId": "10737638498661133063"
     },
     "user_tz": -120
    },
    "id": "La7xHOvyfxxW"
   },
   "outputs": [],
   "source": [
    "def calculate_tfidf_similarity(inputtext):\n",
    "  if isinstance(inputtext,str):\n",
    "    inputtext = [inputtext]\n",
    "  path = \"../00_data/TF-IDF_Vectorizer\"\n",
    "  vectorizer = load_pickle(path+\"1_vectorizer.pkl\")\n",
    "  tfidf_matrix = load_pickle(path+\"1_tfidf_matrix.pkl\")\n",
    "  #jobtitles = load_pickle(\"/content/drive/MyDrive/TRAINING/data/1_jobnames.pkl\")\n",
    "  escoids = load_pickle(path+\"1_escoids.pkl\")\n",
    "  inputtfidf = vectorizer.transform(inputtext)\n",
    "  cosine_sim = cosine_similarity(inputtfidf, tfidf_matrix)\n",
    "  #cossim_df = pd.DataFrame(cosine_sim, columns = escoids, index=[\"similarity\"]).T.sort_values(by=\"similarity\",ascending=False).reset_index()\n",
    "  #cossim_df.columns = [\"esco_id\",\"similarity\"]\n",
    "  #ranks = list(cossim_df.index+1)\n",
    "  #cossim_df[\"rank\"] = ranks\n",
    "  return cosine_sim#,cossim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1510,
     "status": "ok",
     "timestamp": 1682578746565,
     "user": {
      "displayName": "Lukas Wolfrum",
      "userId": "10737638498661133063"
     },
     "user_tz": -120
    },
    "id": "2i0dSwXagAmN",
    "outputId": "9a317d36-215c-4c7e-b8c0-fea5e04c836f"
   },
   "outputs": [],
   "source": [
    "calculate_tfidf_similarity(testads[\"short_texts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 767,
     "referenced_widgets": [
      "76b5ff71d26e46b694e82ef1dd802e9b",
      "bb2eb8b7a96848a29a0de2ecee8c49ca",
      "0d5133f343394907be0ebf285f0e1d1c",
      "d02c309dfcf34905bff59e23c4b922e0",
      "25a65102e2764097ac4c063e00c9546b",
      "e271358479b84f3dbc4ce60a3de7e2a8",
      "67fd09d7f52041fe878efc2d1582d851",
      "bc1995a8bc4a473fa991148a28b7201b",
      "8e82e80ca5ad4f83aac1cbe657fe5bdf",
      "9a79ef3672d3423db7ffe0c1d2dc8791",
      "52839f9ff9c54fe6a772c35dffddd434",
      "53db8f5e7b3d40c38122e64b619876e3",
      "b768acc3180849b2a2a287ea9281bc24",
      "2f79a69fb0e34065a134ba621906c91c",
      "aeb08f1b2e4c4cc89a7609fec58e8242",
      "f0ec5c3e46e04a0a980c99730af7f500",
      "bf83c0ee20694aeb99e0e24e72790741",
      "34ef3b88add64325b0255fd257794a73",
      "9c5222fa09544a4086ed0689f7bbef48",
      "02489c33e55f42a1a57c42dc0cf7dd5b",
      "3740a2a3d19a496ca23979c960e8d66b",
      "c719682e1b2444de8c03b6ebab8ba053"
     ]
    },
    "executionInfo": {
     "elapsed": 103036,
     "status": "ok",
     "timestamp": 1684239610509,
     "user": {
      "displayName": "Lukas Wolfrum",
      "userId": "10737638498661133063"
     },
     "user_tz": -120
    },
    "id": "BllvbarBeUMS",
    "outputId": "cde54fab-a16c-4368-afba-bf8b940e7385"
   },
   "outputs": [],
   "source": [
    "MRR = []\n",
    "MRR_AT = 100\n",
    "currently = \"\".join([c for c in str(datetime.now()).split('.')[0] if c.isdigit()])\n",
    "\n",
    "for model_path in paths:\n",
    "  print(f\"Loading Model {model_path}\")\n",
    "  if model_path in [\"agne/jobGBERT\",\"deepset/gbert-base\"]:\n",
    "    model = SentenceTransformer(model_path)\n",
    "    embeddings = encode_jobs(model)\n",
    "  else:\n",
    "    model = SentenceTransformer(f\"/content/drive/MyDrive/TRAINING/_COSINESIM/content/{model_path}\")\n",
    "    embeddings = load_pickle(f\"/content/drive/MyDrive/TRAINING/_COSINESIM/content/{model_path}embeddings.pkl\")\n",
    "  print(embeddings.keys())\n",
    "  print(\"Creating Embeddings.\")\n",
    "  encodings_short = model.encode(list(testads[\"short_texts\"]), show_progress_bar=True)\n",
    "  #encodings_long = model.encode(list(testads[\"description\"]), show_progress_bar=True) \n",
    "\n",
    "  testads[\"embeddings_short\"] = encodings_short.tolist()\n",
    "  #testads[\"embeddings_long\"] = encodings_long.tolist()\n",
    "\n",
    "  print(\"Finished creating Embeddings. Evaluating.\")\n",
    "\n",
    "  for textkind in [\"embeddings_short\"]:\n",
    "    similarities = {}\n",
    "    for k in [\"job_centroid\"]:\n",
    "        similarities_bert = (util.cos_sim(testads[textkind],embeddings[k][\"embeddings\"]))\n",
    "        similarities[k+\"_woTFIDF\"] = similarities_bert\n",
    "\n",
    "        max_influence_tfidf = (max(map(max, similarities_bert))).item()*0.2\n",
    "        similarities_tfidf = calculate_tfidf_similarity(testads[\"short_texts\"])\n",
    "        similarities_tfidf *= max_influence_tfidf/similarities_tfidf.max()\n",
    "        \n",
    "        similarities_combi = np.add(similarities_bert,similarities_tfidf)\n",
    "        similarities[k+\"_wTFIDF\"] = similarities_combi\n",
    "    print(similarities.keys())\n",
    "    for k in similarities:\n",
    "      ranks = []\n",
    "      missing = 0\n",
    "      simdf = pd.DataFrame(similarities[k],columns=embeddings[\"job_centroid\"][\"esco_id\"], index=testads[\"esco_id\"])\n",
    "      for i in tqdm(range(len(simdf))):\n",
    "        id = simdf.iloc[i].name\n",
    "        series = simdf.iloc[i].sort_values(ascending=False).reset_index()\n",
    "        #print(series)\n",
    "        rank = (series[series[\"index\"]==id].index.item()+1)\n",
    "        #print(rank)\n",
    "        if rank > MRR_AT:\n",
    "          missing +=1\n",
    "          ranks.append(0)\n",
    "        else:\n",
    "          ranks.append(1/rank)\n",
    "      missing = missing/len(simdf)\n",
    "      MRR.append({\"model\":model_path.split(\"/\")[-2],\"textkind\": textkind,\"embedding_kind\":k, \"MRR\":np.mean(ranks), \"missing\":missing, \"MRR@\":MRR_AT})\n",
    "      df = pd.DataFrame(MRR).sort_values(by=[\"MRR\"], ascending=[False]).reset_index(drop=True)\n",
    "      display(df)\n",
    "      df.to_excel(f\"../00_data/SBERT_Models/Evaluation/{currently}_evaluation.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOBFOeu3OazzwfiLS06TnIZ",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02489c33e55f42a1a57c42dc0cf7dd5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0d5133f343394907be0ebf285f0e1d1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bc1995a8bc4a473fa991148a28b7201b",
      "max": 71,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8e82e80ca5ad4f83aac1cbe657fe5bdf",
      "value": 71
     }
    },
    "25a65102e2764097ac4c063e00c9546b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2f79a69fb0e34065a134ba621906c91c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9c5222fa09544a4086ed0689f7bbef48",
      "max": 71,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_02489c33e55f42a1a57c42dc0cf7dd5b",
      "value": 71
     }
    },
    "34ef3b88add64325b0255fd257794a73": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3740a2a3d19a496ca23979c960e8d66b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "52839f9ff9c54fe6a772c35dffddd434": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "53db8f5e7b3d40c38122e64b619876e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b768acc3180849b2a2a287ea9281bc24",
       "IPY_MODEL_2f79a69fb0e34065a134ba621906c91c",
       "IPY_MODEL_aeb08f1b2e4c4cc89a7609fec58e8242"
      ],
      "layout": "IPY_MODEL_f0ec5c3e46e04a0a980c99730af7f500"
     }
    },
    "67fd09d7f52041fe878efc2d1582d851": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "76b5ff71d26e46b694e82ef1dd802e9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bb2eb8b7a96848a29a0de2ecee8c49ca",
       "IPY_MODEL_0d5133f343394907be0ebf285f0e1d1c",
       "IPY_MODEL_d02c309dfcf34905bff59e23c4b922e0"
      ],
      "layout": "IPY_MODEL_25a65102e2764097ac4c063e00c9546b"
     }
    },
    "8e82e80ca5ad4f83aac1cbe657fe5bdf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9a79ef3672d3423db7ffe0c1d2dc8791": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c5222fa09544a4086ed0689f7bbef48": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aeb08f1b2e4c4cc89a7609fec58e8242": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3740a2a3d19a496ca23979c960e8d66b",
      "placeholder": "​",
      "style": "IPY_MODEL_c719682e1b2444de8c03b6ebab8ba053",
      "value": " 71/71 [00:09&lt;00:00, 18.98it/s]"
     }
    },
    "b768acc3180849b2a2a287ea9281bc24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bf83c0ee20694aeb99e0e24e72790741",
      "placeholder": "​",
      "style": "IPY_MODEL_34ef3b88add64325b0255fd257794a73",
      "value": "Batches: 100%"
     }
    },
    "bb2eb8b7a96848a29a0de2ecee8c49ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e271358479b84f3dbc4ce60a3de7e2a8",
      "placeholder": "​",
      "style": "IPY_MODEL_67fd09d7f52041fe878efc2d1582d851",
      "value": "Batches: 100%"
     }
    },
    "bc1995a8bc4a473fa991148a28b7201b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf83c0ee20694aeb99e0e24e72790741": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c719682e1b2444de8c03b6ebab8ba053": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d02c309dfcf34905bff59e23c4b922e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9a79ef3672d3423db7ffe0c1d2dc8791",
      "placeholder": "​",
      "style": "IPY_MODEL_52839f9ff9c54fe6a772c35dffddd434",
      "value": " 71/71 [00:09&lt;00:00, 12.12it/s]"
     }
    },
    "e271358479b84f3dbc4ce60a3de7e2a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f0ec5c3e46e04a0a980c99730af7f500": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
