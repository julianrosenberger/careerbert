{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gWOOQk0qg2Yz"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from _utils import flatten_list, load_json,write_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AkkomPGdV3dV"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import models, losses, util\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from sentence_transformers import evaluation\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from training_helpers import load_data_pairs, create_trainig_samples, encode_jobs\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import KFold\n",
    "from transformers import set_seed\n",
    "import accelerate\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xSp9eTjdnZWD"
   },
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = load_data_pairs()\n",
    "positive_pairs = flatten_list([data_dict[x] for x in data_dict if \"pos\" in x])\n",
    "negative_pairs = flatten_list([data_dict[x] for x in data_dict if \"neg\" in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"../00_data/SBERT_Models/models/gbert_TSDAE_epochs5\"\n",
    "model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == \"deepset/gbert\":\n",
    "  TSDAE = \"woTSDAE\"\n",
    "elif model_name == \"../00_data/SBERT_Models/models/gbert_TSDAE_epochs5\":\n",
    "  TSDAE = \"wTSDAE\"\n",
    "else:\n",
    "  raise TypeError\n",
    "\n",
    "batch_size = 16\n",
    "lr = 2e-5\n",
    "num_epochs = 1\n",
    "fold_size = 10\n",
    "output_path = f\"../00_data/SBERT_Models/models/gbert_batch{batch_size}_{TSDAE}_{lr}_f{fold_size}\"\n",
    "output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hWnxsnraA76J"
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=fold_size, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform training and evaluation for each fold\n",
    "for epoch, (train_index, dev_index) in enumerate(kf.split(positive_pairs)):\n",
    "    # Split data into training and development sets\n",
    "    pos_train_samples = [positive_pairs[i] for i in train_index]\n",
    "    pos_dev_samples = [positive_pairs[i] for i in dev_index]\n",
    "    warmup_steps = len(pos_train_samples) * 0.1\n",
    "\n",
    "    # Create training examples\n",
    "    train_examples = [InputExample(texts=[item[0], item[1]]) for item in pos_train_samples]\n",
    "    train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=batch_size)\n",
    "    train_loss = losses.MultipleNegativesRankingLoss(SentenceTransformer(model_name))\n",
    "\n",
    "    # Define evaluator\n",
    "    evaluator = evaluation.RerankingEvaluator(pos_dev_samples, at_k=100, show_progress_bar=True)\n",
    "\n",
    "    # Train the model\n",
    "    SentenceTransformer(model_name).fit(\n",
    "        train_objectives=[(train_dataloader, train_loss)],\n",
    "        epochs=num_epochs,\n",
    "        warmup_steps=warmup_steps,\n",
    "        evaluator=evaluator,\n",
    "        output_path=output_path\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPOVltfMm9syHPl4fxxi3lm",
   "gpuClass": "premium",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
