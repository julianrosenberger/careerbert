{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of Embedding Set for Job Advertisements\n",
    "This notebook processes job advertisements scraped from the EURES portal to create an embedding dataset. It includes steps for cleaning, extending, and merging job data with ESCO job IDs. The final output is a structured dataset ready for embedding generation and further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this notebook, the Job advertisembnts for the Embedding Set is created"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "### This section imports all necessary libraries and modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom utilities and Selenium modules for web scraping\n",
    "import sys\n",
    "sys.path.append('..')  # Adjust path to include parent directory\n",
    "from _utils import load_json, flatten_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries and third-party modules\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "random.seed(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main\n",
    "#### This section contains the main logic for processing job advertisements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _helpers_parsing import parse_multithreading_eures, extend_jobs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas for data manipulation\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Load and clean the overview data\n",
    "overview = pd.DataFrame(load_json(\"../00_data/EURES/eures_overview_total.json\"))\n",
    "print(len(overview))\n",
    "overview = overview.drop_duplicates([\"title\", \"url\"])\n",
    "print(len(overview))\n",
    "overview = overview[~overview[\"title\"].isnull()]\n",
    "print(len(overview))\n",
    "overview.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add ESCO IDs\n",
    "### Extend job advertisements with ESCO job IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ESCO lookup dictionary\n",
    "esco_lookup_dict = load_json(\"../00_data/ESCO/esco_lookup.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Extend dataset to full length\n",
    "ads_extended = pd.DataFrame(flatten_list(overview.progress_apply(extend_jobs, axis=1)))\n",
    "print(len(ads_extended))\n",
    "ads_extended = ads_extended[~ads_extended[\"esco_id\"].isnull()]\n",
    "print(len(ads_extended))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Get unique ESCO IDs from unparsed advertisements\n",
    "unique_ids_unparsed = list(ads_extended[\"esco_id\"].unique())\n",
    "len(unique_ids_unparsed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Parsed Ads\n",
    "# Load already parsed job advertisements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Load parsed job advertisements\n",
    "parsed_jobads = pd.DataFrame(load_json(\"../00_data/EURES/parsed_ads_final.json\"))\n",
    "len(parsed_jobads)\n",
    "desc_lookup = parsed_jobads[[\"url\",\"description\"]].drop_duplicates([\"url\", \"description\"])\n",
    "len(desc_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Display parsed job advertisements\n",
    "parsed_jobads.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Check of Descriptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if description contains alphabetic characters\n",
    "def alphabetic_char(description):\n",
    "    for c in description:\n",
    "        if c.isalpha():\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Add quality metrics to descriptions\n",
    "desc_lookup[\"has_alpha\"] = desc_lookup[\"description\"].apply(alphabetic_char)\n",
    "desc_lookup[\"length\"] = desc_lookup[\"description\"].apply(len)\n",
    "desc_lookup.sort_values(by=\"length\").iloc[5][\"description\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging Overview with Already Parsed Ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Merge overview with parsed job advertisements\n",
    "parsed_jobads = pd.merge(ads_extended,desc_lookup, on=\"url\",how=\"left\")\n",
    "print(len(parsed_jobads))\n",
    "# Parsing errors in some descriptions\n",
    "parsed_jobads = parsed_jobads[~parsed_jobads[\"description\"].isna()]\n",
    "print(len(parsed_jobads))\n",
    "parsed_jobads = parsed_jobads[~parsed_jobads[\"esco_id\"].isna()]\n",
    "print(len(parsed_jobads))\n",
    "unique_ids_parsed = list(parsed_jobads[\"esco_id\"].unique())\n",
    "print(f\"({len(unique_ids_parsed)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Check for missing ESCO IDs\n",
    "if len(unique_ids_unparsed) != len(unique_ids_parsed):\n",
    "    print(f\"{len(unique_ids_unparsed)}/{len(unique_ids_parsed)}\")\n",
    "    set_missing_ids = set(unique_ids_unparsed)-set(unique_ids_parsed)\n",
    "    missing_ids = []\n",
    "    for id in set_missing_ids:\n",
    "        missing_ids.append({\"esco_id\":id, \"count\":0, \"need\":100})\n",
    "    missing_ids =pd.DataFrame(missing_ids)\n",
    "missing_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count numbers of ESCO IDs and merge on overview\n",
    "counts = pd.DataFrame(parsed_jobads[\"esco_id\"].value_counts()).reset_index()\n",
    "counts.columns = [\"esco_id\",\"count\"]\n",
    "parsed_jobads = pd.merge(parsed_jobads, counts, on=\"esco_id\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Overview Over Job Ads Which Are still missing in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Identify job advertisements in need\n",
    "in_need = counts[counts[\"count\"]<100].copy()\n",
    "in_need[\"need\"] = 100-in_need[\"count\"]\n",
    "print(len(in_need))\n",
    "in_need = pd.concat([in_need, missing_ids])\n",
    "print(len(in_need))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Create set of URLs that have already been parsed\n",
    "parsed_urls = (set(parsed_jobads[\"url\"]))\n",
    "deadlinks = set(load_json(\"../00_data/EURES/deadlinks_final.json\"))\n",
    "len(deadlinks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Overview to Unparsed URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Filter unparsed URLs from the overview\n",
    "print(len(ads_extended))\n",
    "unparsed_url_df = ads_extended[~ads_extended[\"url\"].isin(parsed_urls)]\n",
    "print(len(unparsed_url_df))\n",
    "unparsed_url_df = unparsed_url_df[~unparsed_url_df[\"url\"].isin(deadlinks)]\n",
    "print(len(unparsed_url_df))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a DataFrame of URLs to parse based on needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Filter URLs to parse based on needs\n",
    "jobads_to_parse = []\n",
    "for need in tqdm(in_need.to_dict(\"records\")):\n",
    "    filtered_need = unparsed_url_df[unparsed_url_df[\"esco_id\"]==need[\"esco_id\"]].iloc[0:need[\"need\"]].to_dict(\"records\")\n",
    "    if len(filtered_need) > 0:\n",
    "        jobads_to_parse += filtered_need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame of URLs to parse\n",
    "to_parse_df = pd.DataFrame(jobads_to_parse)\n",
    "to_parse_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse job advertisements using multithreading\n",
    "results = parse_multithreading_eures(to_parse_df,[], headless=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Load and display parsed advertisements\n",
    "parsed_ads = (load_json(\"../00_data/EURES/parsed_ads_final.json\"))\n",
    "len(parsed_ads)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "careerbert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
